{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1hi1dibkHyFbaxAteLlZJw6r3g9ddd4Lf\n",
      "From (redirected): https://drive.google.com/uc?id=1hi1dibkHyFbaxAteLlZJw6r3g9ddd4Lf&confirm=t&uuid=19f496fc-41e8-4478-b6a1-2508f41c8bed\n",
      "To: /home/hyj/ChanHyung/Audio/DACON_fake_voice_detection/dataset/dacon_dataset.zip\n",
      "100%|██████████| 3.31G/3.31G [02:07<00:00, 26.0MB/s]\n",
      "Extracting files: 100%|██████████| 106708/106708 [00:24<00:00, 4304.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and extracted to ./dataset/dacon_dataset\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gdown\n",
    "from zipfile import ZipFile\n",
    "from tqdm import tqdm\n",
    "\n",
    "file_id = \"1hi1dibkHyFbaxAteLlZJw6r3g9ddd4Lf\"\n",
    "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "\n",
    "download_path = \"./dataset/dacon_dataset.zip\"\n",
    "extract_path = \"./dataset/dacon_dataset\"\n",
    "\n",
    "if not os.path.exists(extract_path):\n",
    "    os.makedirs(extract_path)\n",
    "\n",
    "gdown.download(url, download_path, quiet=False)\n",
    "\n",
    "with ZipFile(download_path, 'r') as zip_ref:\n",
    "    for file in tqdm(zip_ref.namelist(), desc='Extracting files'):\n",
    "        zip_ref.extract(file, extract_path)\n",
    "\n",
    "os.remove(download_path)\n",
    "\n",
    "print(f\"File downloaded and extracted to {extract_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denosing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyj/anaconda3/envs/DACON_DEEPFAKE/lib/python3.11/site-packages/df/io.py:9: UserWarning: `torchaudio.backend.common.AudioMetaData` has been moved to `torchaudio.AudioMetaData`. Please update the import path.\n",
      "  from torchaudio.backend.common import AudioMetaData\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import math\n",
    "import os\n",
    "import tempfile\n",
    "import time\n",
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "import gradio as gr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from loguru import logger\n",
    "from PIL import Image\n",
    "from torch import Tensor\n",
    "\n",
    "from df import config\n",
    "from df.enhance import enhance, init_df, load_audio, save_audio\n",
    "from df.io import resample\n",
    "\n",
    "from torchaudio import AudioMetaData "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/hyj/ChanHyung/Audio/DACON_fake_voice_detection'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "base_path = os.getcwd()\n",
    "train_df = pd.read_csv(f'{base_path}/dataset/dacon_dataset/train.csv')\n",
    "test_df = pd.read_csv(f'{base_path}/dataset/dacon_dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audiomentations import BandStopFilter\n",
    "augment = BandStopFilter(min_center_freq=100., max_center_freq=8000.0, min_bandwidth_fraction=0.1, max_bandwidth_fraction=0.4, p=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-23 02:40:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mRunning on torch 2.3.0\u001b[0m\n",
      "\u001b[32m2024-07-23 02:40:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mRunning on host cvlab\u001b[0m\n",
      "\u001b[32m2024-07-23 02:40:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mLoading model settings of DeepFilterNet2\u001b[0m\n",
      "\u001b[32m2024-07-23 02:40:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mInitializing model `deepfilternet2`\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: not a git repository (or any of the parent directories): .git\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-23 02:40:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mFound checkpoint /home/hyj/ChanHyung/Audio/DACON_fake_voice_detection/DeepFilterNet2/checkpoints/model_96.ckpt.best with epoch 96\u001b[0m\n",
      "\u001b[32m2024-07-23 02:40:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mRunning on device cuda:0\u001b[0m\n",
      "\u001b[32m2024-07-23 02:40:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mModel loaded\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/55438 [00:00<?, ?it/s]\u001b[32m2024-07-23 02:40:32\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[33m\u001b[1mAudio sampling rate does not match model sampling rate (32000, 48000). Resampling...\u001b[0m\n",
      " 19%|█▊        | 10345/55438 [14:33<51:15, 14.66it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "너무 짧아서 안됨: WQNMJRXI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 26770/55438 [38:31<39:36, 12.06it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "너무 짧아서 안됨: ALKRDVFF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55438/55438 [1:19:58<00:00, 11.55it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "dir_name = 'train_bandstop_denoising'\n",
    "\n",
    "os.makedirs(os.path.join(base_path, 'dataset', 'dacon_dataset', dir_name), exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model, df, _ = init_df(os.path.join(base_path, 'DeepFilterNet2'), config_allow_defaults=True)\n",
    "model = model.to(device=device).eval()\n",
    "train_x = os.listdir(os.path.join(base_path, 'dataset', 'dacon_dataset', 'train'))\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(train_x))):\n",
    "    id = train_x[i].split('/')[-1].split('.')[0]\n",
    "    try: \n",
    "        path = os.path.join(base_path, 'dataset', 'dacon_dataset', 'train', train_x[i])\n",
    "        sr = config(\"sr\", 32000, int, section=\"df\")\n",
    "        sample, meta = load_audio(path, sr)\n",
    "        sample = augment(sample.numpy(), sample_rate=48000)\n",
    "        sample = torch.from_numpy(sample)\n",
    "        enhanced = enhance(model, df, sample)\n",
    "\n",
    "        lim = torch.linspace(0.0, 1.0, int(sr * 0.15)).unsqueeze(0)\n",
    "        lim = torch.cat((lim, torch.ones(1, enhanced.shape[1] - lim.shape[1])), dim=1)\n",
    "        enhanced = enhanced * lim\n",
    "        if meta.sample_rate != sr:\n",
    "            enhanced = resample(enhanced, sr, meta.sample_rate)\n",
    "            sample = resample(sample, sr, meta.sample_rate)\n",
    "            sr = meta.sample_rate\n",
    "\n",
    "        noisy_wav = os.path.join(base_path, 'noisy_wav1551.wav')\n",
    "        save_audio(noisy_wav, sample, sr)\n",
    "        enhanced_wav = os.path.join(base_path, 'enhanced_wav1551.wav') \n",
    "        save_audio(enhanced_wav, enhanced, sr)\n",
    "        noisy_wav = os.path.join(base_path, 'dataset', 'dacon_dataset', dir_name, f'noisy_{id}.wav')\n",
    "        shutil.move(os.path.join(base_path, 'noisy_wav1551.wav'), noisy_wav)\n",
    "        enhanced_wav = os.path.join(base_path, 'dataset', 'dacon_dataset', dir_name, f'enhanced_{id}.wav')\n",
    "        shutil.move(os.path.join(base_path, 'enhanced_wav1551.wav') ,  enhanced_wav)\n",
    "    except:\n",
    "        print(f\"너무 짧아서 안됨: {id}\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file_list = [os.path.join(base_path, 'dataset', 'dacon_dataset', 'train', i) \n",
    "                   for i in os.listdir(os.path.join(base_path, 'dataset', 'dacon_dataset', 'train'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchvision is not available - cannot save figures\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55436/55436 [5:33:52<00:00,  2.77it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All boundaries and audio lengths have been saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "from speechbrain.inference.VAD import VAD\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# VAD 모델 초기화\n",
    "vad_model = VAD.from_hparams(source=\"speechbrain/vad-crdnn-libriparty\", savedir=\"pretrained_models/vad-crdnn-libriparty\")\n",
    "\n",
    "\n",
    "# 타겟 샘플링 레이트\n",
    "target_sample_rate = 16000\n",
    "\n",
    "# 음성 구간 정보를 저장할 디렉토리\n",
    "output_dir = os.path.join(base_path, 'vad_bandstop_boundaries')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 오디오 파일 처리\n",
    "for input_file in tqdm(audio_file_list):\n",
    "    # Step 1: 오디오 파일 로드 및 샘플링 레이트 변환\n",
    "    signal, original_sample_rate = torchaudio.load(input_file)\n",
    "    transform = torchaudio.transforms.Resample(orig_freq=original_sample_rate, new_freq=target_sample_rate)\n",
    "    resampled_signal = transform(signal)\n",
    "    \n",
    "    # 오디오 길이 계산 (초 단위)\n",
    "    audio_length = resampled_signal.size(1) / target_sample_rate\n",
    "    \n",
    "    # 임시 파일로 저장\n",
    "    temp_output_file = os.path.join(base_path, 'temp_resampled_audio_file2.wav')\n",
    "    torchaudio.save(temp_output_file, resampled_signal, target_sample_rate)\n",
    "    \n",
    "    # Step 2: 변환된 파일로 VAD 수행\n",
    "    boundaries = vad_model.get_speech_segments(temp_output_file)\n",
    "    \n",
    "    # Step 3: 각 음성 구간의 시작 시간과 종료 시간을 기록\n",
    "    base_filename = os.path.splitext(os.path.basename(input_file))[0]\n",
    "    boundaries_list = []\n",
    "    for boundary in boundaries:\n",
    "        start, end = boundary[0].item(), boundary[1].item()\n",
    "        boundaries_list.append({\n",
    "            \"start\": start,\n",
    "            \"end\": end\n",
    "        })\n",
    "    \n",
    "    # JSON 파일로 저장\n",
    "    output_data = {\n",
    "        \"audio_length\": audio_length,\n",
    "        \"boundaries\": boundaries_list\n",
    "    }\n",
    "    boundaries_filename = f\"{base_filename}_boundaries.json\"\n",
    "    boundaries_filepath = os.path.join(output_dir, boundaries_filename)\n",
    "    with open(boundaries_filepath, 'w') as f:\n",
    "        json.dump(output_data, f)\n",
    "    \n",
    "    # print(f\"Saved boundaries and audio length for {input_file} to {boundaries_filepath}\")\n",
    "    \n",
    "    # 임시 파일 삭제\n",
    "    os.remove(temp_output_file)\n",
    "\n",
    "print(\"All boundaries and audio lengths have been saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make (0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSON files: 100%|██████████| 55436/55436 [01:29<00:00, 619.31it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import librosa\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 경로 설정\n",
    "json_dir = os.path.join(base_path, 'vad_bandstop_boundaries')\n",
    "audio_dir = os.path.join(base_path, 'dataset', 'dacon_dataset', 'train_bandstop_denoising')\n",
    "output_dir = os.path.join(base_path, 'dataset', 'dacon_dataset', 'train_silent')\n",
    "\n",
    "\n",
    "# 출력 디렉토리 생성\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 스킵할 이름 리스트\n",
    "skip_names = [\n",
    "    \"XVYZXEIZ\", \"ODYZCZMF\", \"EHKFWHIN\", \"LSDLYESX\", \"KNBWYZNI\",\n",
    "    \"ILYTDFAJ\", \"ENXDYYVM\", \"TTDERPVZ\", \"LPSIJBXB\", \"CHSDQDKV\",\n",
    "    \"MRNJWEFU\", \"EBJXOVTJ\", \"MXDGGMDP\", \"VSLMVONT\", \"XFZFVHLE\",\n",
    "    \"OGZHVEUS\", \"FVFYPRZP\", \"WQNMJRXI\", \"ALKRDVFF\"\n",
    "]\n",
    "\n",
    "# JSON 파일 목록 가져오기\n",
    "json_files = [f for f in os.listdir(json_dir) if f.endswith('_boundaries.json')]\n",
    "\n",
    "# JSON 파일 처리\n",
    "for json_file in tqdm(json_files, desc=\"Processing JSON files\"):\n",
    "    name = json_file.replace('_boundaries.json', '')\n",
    "    \n",
    "    # 스킵할 이름인지 확인\n",
    "    if name in skip_names:\n",
    "        continue\n",
    "    \n",
    "    # JSON 파일 경로\n",
    "    json_path = os.path.join(json_dir, json_file)\n",
    "    \n",
    "    # 오디오 파일 경로\n",
    "    audio_path = os.path.join(audio_dir, f\"{name}.wav\")\n",
    "    \n",
    "    # JSON 파일 읽기\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # 오디오 파일 읽기\n",
    "    audio_data, sr = librosa.load(audio_path, sr=None)\n",
    "    \n",
    "    # boundaries 가져오기\n",
    "    boundaries = data.get('boundaries', [])\n",
    "    \n",
    "    # 간격 설정 (여기서는 0.1초를 추가로 잘라냅니다)\n",
    "    margin = 0.1  # 100 milliseconds\n",
    "    \n",
    "    if not boundaries:\n",
    "        # boundaries가 없으면 전체 오디오 데이터 사용\n",
    "        cropped_audio = audio_data\n",
    "    else:\n",
    "        # 제외할 구간 설정\n",
    "        exclude_intervals = [(max(boundary['start'] - margin, 0), min(boundary['end'] + margin, len(audio_data) / sr)) for boundary in boundaries]\n",
    "        \n",
    "        # 제외할 구간을 제외한 오디오 데이터 생성\n",
    "        keep_samples = []\n",
    "        prev_end = 0.0\n",
    "        for start, end in exclude_intervals:\n",
    "            if prev_end < start:\n",
    "                keep_samples.append(audio_data[int(prev_end * sr):int(start * sr)])\n",
    "            prev_end = end\n",
    "        if prev_end * sr < len(audio_data):\n",
    "            keep_samples.append(audio_data[int(prev_end * sr):])\n",
    "        \n",
    "        # 모든 유지할 샘플들을 합침\n",
    "        cropped_audio = np.concatenate(keep_samples) if keep_samples else np.array([], dtype=audio_data.dtype)\n",
    "    \n",
    "    # 결과 오디오 파일 저장\n",
    "    output_audio_path = os.path.join(output_dir, f\"cropped_{name}.wav\")\n",
    "    sf.write(output_audio_path, cropped_audio, sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Merging audio files: 100%|██████████| 55436/55436 [00:05<00:00, 10755.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged audio file saved at /home/hyj/ChanHyung/Audio/DACON_fake_voice_detection/merged_audio.wav\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 경로 설정\n",
    "output_dir = os.path.join(base_path, 'dataset', 'dacon_dataset', 'train_silent')\n",
    "merged_output_path = os.path.join(base_path, 'merged_audio.wav')\n",
    "\n",
    "\n",
    "# 병합할 오디오 파일 목록 가져오기\n",
    "audio_files = [os.path.join(output_dir, f) for f in os.listdir(output_dir) if f.endswith('.wav')]\n",
    "\n",
    "# 병합할 오디오 데이터를 저장할 리스트 초기화\n",
    "merged_audio_data = []\n",
    "sample_rate = None\n",
    "\n",
    "# 각 오디오 파일을 읽고 병합\n",
    "for audio_file in tqdm(audio_files, desc=\"Merging audio files\"):\n",
    "    audio_data, sr = sf.read(audio_file)\n",
    "    if sample_rate is None:\n",
    "        sample_rate = sr  # 첫 번째 오디오 파일의 샘플링 레이트 사용\n",
    "    else:\n",
    "        assert sample_rate == sr, f\"Sample rate mismatch: {audio_file}\"\n",
    "    merged_audio_data.append(audio_data)\n",
    "\n",
    "# 병합된 오디오 데이터를 하나의 배열로 결합\n",
    "if merged_audio_data:\n",
    "    merged_audio_data = np.concatenate(merged_audio_data)\n",
    "    # 병합된 오디오 데이터를 새로운 파일로 저장\n",
    "    sf.write(merged_output_path, merged_audio_data, sample_rate)\n",
    "    print(f\"Merged audio file saved at {merged_output_path}\")\n",
    "else:\n",
    "    print(\"No audio files to merge.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1, 0), (0, 1) Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save train segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pydub import AudioSegment\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55438/55438 [02:42<00:00, 341.98it/s]\n"
     ]
    }
   ],
   "source": [
    "import soundfile as sf\n",
    "import json\n",
    "\n",
    "output_base_path = os.path.join(base_path, 'dataset', 'dacon_dataset', 'train_segment')\n",
    "\n",
    "os.makedirs(output_base_path, exist_ok=True)\n",
    "\n",
    "results = []\n",
    "\n",
    "for _, row in tqdm(train_df.iterrows(), total=train_df.shape[0]):\n",
    "    json_path = os.path.join(base_path, 'vad_bandstop_boundaries', f\"enhanced_{row['id']}_boundaries.json\")\n",
    "    \n",
    "\n",
    "    if row['id'] in ['WQNMJRXI', 'ALKRDVFF']:\n",
    "        continue\n",
    "\n",
    "    audio_path = os.path.join(base_path, 'dataset', 'dacon_dataset', 'train_bandstop_denoising', f'enhanced_{row[\"id\"]}.wav')\n",
    "    \n",
    "    # 오디오 파일 로드\n",
    "    data, samplerate = sf.read(audio_path)\n",
    "    \n",
    "    # JSON 파일에서 boundaries 읽기\n",
    "    with open(json_path, 'r') as file:\n",
    "        data_json = json.load(file)\n",
    "        for i, boundary in enumerate(data_json['boundaries']):\n",
    "            start_sample = int(boundary['start'] * samplerate)  # 초를 샘플 인덱스로 변환\n",
    "            end_sample = int(boundary['end'] * samplerate)  # 초를 샘플 인덱스로 변환\n",
    "            \n",
    "            # 잘라낸 오디오 부분 추출\n",
    "            cut_data = data[start_sample:end_sample]\n",
    "            \n",
    "            # 잘라낸 오디오 파일 저장\n",
    "            output_path = f\"{output_base_path}/{row['id']}_part{i}.wav\"\n",
    "            sf.write(output_path, cut_data, samplerate)\n",
    "\n",
    "            results.append({\n",
    "                'id': row['id'],\n",
    "                'path': output_path,\n",
    "                'label': row['label']\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make (1, 0), (0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RUNQPNJF</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RDKEKEVX</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QYHJDOFK</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RSPQNHAO</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ICDBLWYI</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55477</th>\n",
       "      <td>KLDKERGF</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55478</th>\n",
       "      <td>JTGPEAPT</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55480</th>\n",
       "      <td>QULDVNGC</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55481</th>\n",
       "      <td>QAYTRNGK</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55482</th>\n",
       "      <td>NJGPMAJL</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27631 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               path label\n",
       "0      RUNQPNJF  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...  real\n",
       "2      RDKEKEVX  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...  real\n",
       "3      QYHJDOFK  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...  real\n",
       "4      RSPQNHAO  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...  real\n",
       "6      ICDBLWYI  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...  real\n",
       "...         ...                                                ...   ...\n",
       "55477  KLDKERGF  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...  real\n",
       "55478  JTGPEAPT  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...  real\n",
       "55480  QULDVNGC  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...  real\n",
       "55481  QAYTRNGK  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...  real\n",
       "55482  NJGPMAJL  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...  real\n",
       "\n",
       "[27631 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_df = results[results['label'] == 'real']\n",
    "real_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27631/27631 [01:45<00:00, 260.91it/s]\n"
     ]
    }
   ],
   "source": [
    "output_dir = os.path.join(base_path, 'dataset', 'dacon_dataset', 'train_bandstop_new_dataset')\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "file_index = 0\n",
    "datasets = []\n",
    "\n",
    "\n",
    "for index, row in tqdm(real_df.iterrows(), total=real_df.shape[0]):\n",
    "    file_path = row['path']\n",
    "    data, samplerate = sf.read(file_path)\n",
    "\n",
    "    # 5초(5000 밀리초) 단위로 분할\n",
    "    chunk_length_ms = 5000  # 분할 길이 (5초)\n",
    "    chunk_length_samples = int(samplerate * (chunk_length_ms / 1000))\n",
    "\n",
    "    # 각 조각 저장\n",
    "    for i in range(0, len(data), chunk_length_samples):\n",
    "        chunk = data[i:i + chunk_length_samples]\n",
    "        if len(chunk) >= int(samplerate * 0.44):  # 0.44초 이상인 경우에만 저장\n",
    "            output_path = os.path.join(output_dir, f\"TRAIN_{file_index:05d}.wav\")\n",
    "            sf.write(output_path, chunk, samplerate, format='WAV')\n",
    "            file_index += 1\n",
    "\n",
    "            datasets.append({\n",
    "                'id1': row['id'],\n",
    "                'id2': None,\n",
    "                'path': output_path,\n",
    "                'fake': 0,\n",
    "                'real': 1,\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_df = results[results['label'] == 'fake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27856/27856 [00:56<00:00, 495.71it/s]\n"
     ]
    }
   ],
   "source": [
    "output_dir = os.path.join(base_path, 'dataset', 'dacon_dataset', 'train_bandstop_new_dataset')\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "for index, row in tqdm(fake_df.iterrows(), total=fake_df.shape[0]):\n",
    "    file_path = row['path']\n",
    "    data, samplerate = sf.read(file_path)\n",
    "\n",
    "    # 5초(5000 밀리초) 단위로 분할\n",
    "    chunk_length_ms = 5000  # 분할 길이 (5초)\n",
    "    chunk_length_samples = int(samplerate * (chunk_length_ms / 1000))\n",
    "\n",
    "    # 각 조각 저장\n",
    "    for i in range(0, len(data), chunk_length_samples):\n",
    "        chunk = data[i:i + chunk_length_samples]\n",
    "        if len(chunk) >= int(samplerate * 0.44):  # 0.44초 이상인 경우에만 저장\n",
    "            output_path = os.path.join(output_dir, f\"TRAIN_{file_index:05d}.wav\")\n",
    "            sf.write(output_path, chunk, samplerate, format='WAV')\n",
    "            file_index += 1\n",
    "\n",
    "            datasets.append({\n",
    "                'id1': row['id'],\n",
    "                'id2': None,\n",
    "                'path': output_path,\n",
    "                'fake': 1,\n",
    "                'real': 0,\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_no_label = pd.DataFrame(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "      <th>path</th>\n",
       "      <th>fake</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RUNQPNJF</td>\n",
       "      <td>None</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RDKEKEVX</td>\n",
       "      <td>None</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RDKEKEVX</td>\n",
       "      <td>None</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QYHJDOFK</td>\n",
       "      <td>None</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RSPQNHAO</td>\n",
       "      <td>None</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63590</th>\n",
       "      <td>XVFCHHQZ</td>\n",
       "      <td>None</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63591</th>\n",
       "      <td>SZXIACUZ</td>\n",
       "      <td>None</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63592</th>\n",
       "      <td>PXLBTGRH</td>\n",
       "      <td>None</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63593</th>\n",
       "      <td>CGGQGPOQ</td>\n",
       "      <td>None</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63594</th>\n",
       "      <td>CPMKEDIS</td>\n",
       "      <td>None</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63595 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id1   id2                                               path  \\\n",
       "0      RUNQPNJF  None  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "1      RDKEKEVX  None  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "2      RDKEKEVX  None  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "3      QYHJDOFK  None  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "4      RSPQNHAO  None  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "...         ...   ...                                                ...   \n",
       "63590  XVFCHHQZ  None  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "63591  SZXIACUZ  None  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "63592  PXLBTGRH  None  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "63593  CGGQGPOQ  None  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "63594  CPMKEDIS  None  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "\n",
       "       fake  real  \n",
       "0         0     1  \n",
       "1         0     1  \n",
       "2         0     1  \n",
       "3         0     1  \n",
       "4         0     1  \n",
       "...     ...   ...  \n",
       "63590     1     0  \n",
       "63591     1     0  \n",
       "63592     1     0  \n",
       "63593     1     0  \n",
       "63594     1     0  \n",
       "\n",
       "[63595 rows x 5 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_no_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake Ratio: 43.71%\n",
      "Real Ratio: 56.29%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# fake, real 비율 계산\n",
    "fake_ratio = train_df_no_label['fake'].mean()\n",
    "real_ratio = train_df_no_label['real'].mean()\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Fake Ratio: {fake_ratio:.2%}\")\n",
    "print(f\"Real Ratio: {real_ratio:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27798, 35797)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_no_label['fake'].sum(), train_df_no_label['real'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "      <th>path</th>\n",
       "      <th>fake</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RUNQPNJF</td>\n",
       "      <td>None</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RDKEKEVX</td>\n",
       "      <td>None</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RDKEKEVX</td>\n",
       "      <td>None</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QYHJDOFK</td>\n",
       "      <td>None</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RSPQNHAO</td>\n",
       "      <td>None</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63590</th>\n",
       "      <td>XVFCHHQZ</td>\n",
       "      <td>None</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63591</th>\n",
       "      <td>SZXIACUZ</td>\n",
       "      <td>None</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63592</th>\n",
       "      <td>PXLBTGRH</td>\n",
       "      <td>None</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63593</th>\n",
       "      <td>CGGQGPOQ</td>\n",
       "      <td>None</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63594</th>\n",
       "      <td>CPMKEDIS</td>\n",
       "      <td>None</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63595 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id1   id2                                               path  \\\n",
       "0      RUNQPNJF  None  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "1      RDKEKEVX  None  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "2      RDKEKEVX  None  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "3      QYHJDOFK  None  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "4      RSPQNHAO  None  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "...         ...   ...                                                ...   \n",
       "63590  XVFCHHQZ  None  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "63591  SZXIACUZ  None  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "63592  PXLBTGRH  None  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "63593  CGGQGPOQ  None  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "63594  CPMKEDIS  None  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "\n",
       "       fake  real  \n",
       "0         0     1  \n",
       "1         0     1  \n",
       "2         0     1  \n",
       "3         0     1  \n",
       "4         0     1  \n",
       "...     ...   ...  \n",
       "63590     1     0  \n",
       "63591     1     0  \n",
       "63592     1     0  \n",
       "63593     1     0  \n",
       "63594     1     0  \n",
       "\n",
       "[63595 rows x 5 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = train_df_no_label\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Fake * 2, Real * 2 Fake and Real "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 32/32202 [00:00<03:21, 159.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32202/32202 [02:24<00:00, 223.13it/s]\n",
      "100%|██████████| 24203/24203 [02:10<00:00, 185.21it/s]\n",
      "100%|██████████| 60000/60000 [04:51<00:00, 205.88it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from pydub import AudioSegment\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def combine_audios(audio1_path, audio2_path, fake, real, i):\n",
    "    try:\n",
    "        # Load the audio files\n",
    "        audio1 = AudioSegment.from_file(audio1_path)\n",
    "        audio2 = AudioSegment.from_file(audio2_path)\n",
    "        \n",
    "        # Ensure both audios are shorter than 5 seconds\n",
    "        audio1 = audio1.set_frame_rate(32000)[:5000]\n",
    "        audio2 = audio2.set_frame_rate(32000)[:5000]\n",
    "\n",
    "        # Determine the lengths of the audio files in samples\n",
    "        len_audio1 = len(audio1)\n",
    "        len_audio2 = len(audio2)\n",
    "\n",
    "        # Determine random start positions\n",
    "        start1 = random.randint(0, max(0, 5000 - len_audio1))\n",
    "        start2 = random.randint(0, max(0, 5000 - len_audio2))\n",
    "\n",
    "        # Create a silent audio segment of 5 seconds\n",
    "        combined = AudioSegment.silent(duration=5000, frame_rate=32000)\n",
    "\n",
    "        # Overlay the audios at the random start positions\n",
    "        combined = combined.overlay(audio1, position=start1)\n",
    "        combined = combined.overlay(audio2, position=start2)\n",
    "        \n",
    "        # Define the output path\n",
    "        \n",
    "        new_path = os.path.join(base_path, 'dataset', 'dacon_dataset', 'train_bandstop_new_dataset', f\"TRAIN_{i:05d}.wav\")\n",
    "\n",
    "        # Ensure the directory exists\n",
    "        os.makedirs(os.path.dirname(new_path), exist_ok=True)\n",
    "        \n",
    "        # Export the combined audio\n",
    "        combined.export(new_path, format=\"wav\")\n",
    "        \n",
    "        # Return metadata for the combined audio\n",
    "        return {\n",
    "            'id1': audio1_path,\n",
    "            'id2': audio2_path,\n",
    "            'path': new_path,\n",
    "            'fake': fake,\n",
    "            'real': real\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing files {audio1_path} and {audio2_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_combinations(df1, df2, fake, real, target_count, start_index):\n",
    "    new_results = []\n",
    "    for i in tqdm(range(start_index, start_index + target_count)):\n",
    "        # Ensure different samples are picked from each dataframe\n",
    "        audio1_path = random.choice(list(df1['path']))\n",
    "        audio2_path = random.choice(list(df2['path']))\n",
    "        while audio1_path == audio2_path:\n",
    "            audio1_path = random.choice(list(df1['path']))\n",
    "            audio2_path = random.choice(list(df2['path']))\n",
    "        result = combine_audios(audio1_path, audio2_path, fake, real, i)\n",
    "        if result:\n",
    "            new_results.append(result)\n",
    "    return new_results\n",
    "\n",
    "# Assuming train_new_dataset.csv contains paths to audio files and a column 'type' indicating 'fake' or 'real'\n",
    "df = result_df.copy()\n",
    "\n",
    "fake_df = df[df['fake'] == 1]\n",
    "real_df = df[df['real'] == 1]\n",
    "\n",
    "# Example usage:\n",
    "start_index = len(result_df)\n",
    "new_results = []\n",
    "\n",
    "(43977, 35875)\n",
    "\n",
    "new_results.extend(create_combinations(fake_df, fake_df, fake=2, real=0, target_count=60000-result_df['fake'].sum(), start_index=start_index))\n",
    "start_index += 60000-result_df['fake'].sum()\n",
    "new_results.extend(create_combinations(real_df, real_df, fake=0, real=2, target_count=60000-result_df['real'].sum(), start_index=start_index))\n",
    "start_index += 60000-result_df['real'].sum()\n",
    "new_results.extend(create_combinations(fake_df, real_df, fake=1, real=1, target_count=60000, start_index=start_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "      <th>path</th>\n",
       "      <th>fake</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116400</th>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116401</th>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116402</th>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116403</th>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116404</th>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116405 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      id1  \\\n",
       "0       /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "1       /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "2       /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "3       /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "4       /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "...                                                   ...   \n",
       "116400  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "116401  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "116402  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "116403  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "116404  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "\n",
       "                                                      id2  \\\n",
       "0       /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "1       /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "2       /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "3       /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "4       /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "...                                                   ...   \n",
       "116400  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "116401  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "116402  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "116403  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "116404  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "\n",
       "                                                     path  fake  real  \n",
       "0       /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...     2     0  \n",
       "1       /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...     2     0  \n",
       "2       /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...     2     0  \n",
       "3       /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...     2     0  \n",
       "4       /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...     2     0  \n",
       "...                                                   ...   ...   ...  \n",
       "116400  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...     1     1  \n",
       "116401  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...     1     1  \n",
       "116402  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...     1     1  \n",
       "116403  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...     1     1  \n",
       "116404  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...     1     1  \n",
       "\n",
       "[116405 rows x 5 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_results = pd.DataFrame(new_results)\n",
    "new_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([result_df, new_results], ignore_index=True)\n",
    "combined_df.to_csv(os.path.join(base_path, 'dataset', 'dacon_dataset', 'train_bandstop_new_dataset_addmix.csv'), index=False)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make 0 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "      <th>path</th>\n",
       "      <th>fake</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RUNQPNJF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RDKEKEVX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RDKEKEVX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QYHJDOFK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RSPQNHAO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179995</th>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179996</th>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179997</th>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179998</th>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179999</th>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      id1  \\\n",
       "0                                                RUNQPNJF   \n",
       "1                                                RDKEKEVX   \n",
       "2                                                RDKEKEVX   \n",
       "3                                                QYHJDOFK   \n",
       "4                                                RSPQNHAO   \n",
       "...                                                   ...   \n",
       "179995  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "179996  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "179997  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "179998  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "179999  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "\n",
       "                                                      id2  \\\n",
       "0                                                     NaN   \n",
       "1                                                     NaN   \n",
       "2                                                     NaN   \n",
       "3                                                     NaN   \n",
       "4                                                     NaN   \n",
       "...                                                   ...   \n",
       "179995  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "179996  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "179997  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "179998  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "179999  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...   \n",
       "\n",
       "                                                     path  fake  real  \n",
       "0       /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...     0     1  \n",
       "1       /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...     0     1  \n",
       "2       /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...     0     1  \n",
       "3       /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...     0     1  \n",
       "4       /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...     0     1  \n",
       "...                                                   ...   ...   ...  \n",
       "179995  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...     1     1  \n",
       "179996  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...     1     1  \n",
       "179997  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...     1     1  \n",
       "179998  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...     1     1  \n",
       "179999  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...     1     1  \n",
       "\n",
       "[180000 rows x 5 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = pd.read_csv(os.path.join(base_path, 'dataset', 'dacon_dataset', 'train_bandstop_new_dataset_addmix.csv'))\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_zero_dats = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing audio files: 100%|██████████| 27/27 [00:00<00:00, 230.35it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 경로 설정\n",
    "audio_dir = os.path.join(base_path, 'dataset', 'dacon_dataset', 'train_bandstop_denoising')\n",
    "output_dir = os.path.join(base_path, 'dataset', 'dacon_dataset', 'train_bandstop_new_dataset')\n",
    "\n",
    "\n",
    "# 파일 이름 리스트\n",
    "file_names = [\n",
    "    'GPBVYPQM', 'ZMHQQOIX', 'TSDWJRYK', 'KHETVYDC', 'UCFUFGVP',\n",
    "    'BAUSKCYH', 'NPYSZXLN', 'XWQKSBNA', 'CTBCEJWY', 'IZROHJFG',\n",
    "    'MMWOXBSY', 'NSXAPHSR', 'BTVLPBVC', 'VJPOKGUR', 'SJYXSIFH',\n",
    "    'NHKKJSSF', 'FYQBNCIR', 'AXHPTWRL', 'JBIYWASW', 'UJKRSIJO',\n",
    "    'SANNRLIG', 'QLHQKYHB', 'AZRNUMHQ', 'TJGJDQSC', 'SULPUEVQ',\n",
    "    'YGLREVCI', 'ETJAABZE'\n",
    "]\n",
    "\n",
    "i = 150000\n",
    "\n",
    "# 각 파일 처리\n",
    "for name in tqdm(file_names, desc=\"Processing audio files\"):\n",
    "    # 오디오 파일 경로\n",
    "    audio_path = os.path.join(audio_dir, f\"enhanced_{name}.wav\")\n",
    "    \n",
    "    # 오디오 파일 읽기\n",
    "    audio_data, sr = librosa.load(audio_path, sr=None)\n",
    "    \n",
    "    # 총 길이 (초)\n",
    "    total_duration = librosa.get_duration(y=audio_data, sr=sr)\n",
    "    \n",
    "    # 5초씩 자르기\n",
    "    for start in range(0, int(total_duration), 5):\n",
    "        end = start + 5\n",
    "        if end <= total_duration:\n",
    "            segment = audio_data[int(start * sr):int(end * sr)]\n",
    "            output_audio_path = os.path.join(output_dir, f\"TRAIN_{i:05d}.wav\")\n",
    "            sf.write(output_audio_path, segment, sr)\n",
    "            i += 1\n",
    "            zero_zero_dats.append({\n",
    "                    'id1': audio_path,\n",
    "                    'id2': \"\",\n",
    "                    'path': output_audio_path,\n",
    "                    'fake': 0,\n",
    "                    'real': 0\n",
    "                })\n",
    "            \n",
    "        else:\n",
    "            # 5초 미만의 segment는 저장하지 않음\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing audio segments: 100%|█████████▉| 431/432 [00:01<00:00, 318.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 이 부분은 skip\n",
    "# 00:19-00:20\n",
    "# 00:30-00:37\n",
    "# 14:23-14:25\n",
    "# 28:12-28:13\n",
    "# 29:00-29:04\n",
    "\n",
    "import os\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 경로 설정\n",
    "input_audio_path = os.path.join(base_path, 'merged_audio.wav')\n",
    "output_dir = os.path.join(base_path, 'dataset', 'dacon_dataset', 'train_bandstop_new_dataset')\n",
    "\n",
    "# 출력 디렉토리 생성\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 제외할 구간 (초 단위)\n",
    "exclude_intervals = [\n",
    "    (19, 20),\n",
    "    (30, 37),\n",
    "    (14*60+23, 14*60+25),\n",
    "    (28*60+12, 28*60+13),\n",
    "    (29*60, 29*60+4)\n",
    "]\n",
    "\n",
    "i = 150020\n",
    "\n",
    "# 오디오 파일 읽기\n",
    "audio_data, sr = librosa.load(input_audio_path, sr=None)\n",
    "\n",
    "# 총 길이 (초)\n",
    "total_duration = librosa.get_duration(y=audio_data, sr=sr)\n",
    "\n",
    "# 제외할 구간을 제외한 오디오 데이터 생성\n",
    "keep_samples = []\n",
    "prev_end = 0.0\n",
    "for start, end in sorted(exclude_intervals):\n",
    "    if prev_end < start:\n",
    "        keep_samples.append(audio_data[int(prev_end * sr):int(start * sr)])\n",
    "    prev_end = end\n",
    "if prev_end * sr < len(audio_data):\n",
    "    keep_samples.append(audio_data[int(prev_end * sr):])\n",
    "\n",
    "# 모든 유지할 샘플들을 합침\n",
    "processed_audio = np.concatenate(keep_samples) if keep_samples else np.array([], dtype=audio_data.dtype)\n",
    "\n",
    "# 5초씩 자르기\n",
    "start = 0\n",
    "segment_count = 0\n",
    "for start in tqdm(range(0, len(processed_audio), 5 * sr), desc=\"Processing audio segments\"):\n",
    "    end = start + 5 * sr\n",
    "    if end <= len(processed_audio):\n",
    "        segment = processed_audio[start:end]\n",
    "        output_audio_path = os.path.join(output_dir, f\"TRAIN_{i:05d}.wav\")\n",
    "        sf.write(output_audio_path, segment, sr)\n",
    "        segment_count += 1\n",
    "\n",
    "        i += 1\n",
    "        zero_zero_dats.append({\n",
    "                'id1': audio_path,\n",
    "                'id2': \"\",\n",
    "                'path': output_audio_path,\n",
    "                'fake': 0,\n",
    "                'real': 0\n",
    "            })\n",
    "    else:\n",
    "        # 마지막 segment가 5초 미만이면 저장하지 않음\n",
    "        break\n",
    "\n",
    "print(\"Processing completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "451"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_paths = [i['path'] for i in zero_zero_dats]\n",
    "len(data_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(zero_zero_dats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([combined_df, result_df], ignore_index=True)\n",
    "combined_df.to_csv(os.path.join(base_path, 'dataset', 'dacon_dataset', 'train_bandstop_new_dataset_addmix.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "      <th>path</th>\n",
       "      <th>fake</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>180446</th>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td></td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180447</th>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td></td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180448</th>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td></td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180449</th>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td></td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180450</th>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td></td>\n",
       "      <td>/home/hyj/ChanHyung/Audio/DACON_fake_voice_det...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      id1 id2  \\\n",
       "180446  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...       \n",
       "180447  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...       \n",
       "180448  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...       \n",
       "180449  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...       \n",
       "180450  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...       \n",
       "\n",
       "                                                     path  fake  real  \n",
       "180446  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...     0     0  \n",
       "180447  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...     0     0  \n",
       "180448  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...     0     0  \n",
       "180449  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...     0     0  \n",
       "180450  /home/hyj/ChanHyung/Audio/DACON_fake_voice_det...     0     0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cHb_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
